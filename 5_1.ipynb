{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SET = 'trainingSet-xf.csv'\n",
    "TEST_SET = 'testSet-xf.csv'\n",
    "bin_N = 5\n",
    "\n",
    "def nbc(t_frac):\n",
    "    df = pd.read_csv(TRAINING_SET).sample(frac=t_frac, random_state=47)\n",
    "    df_test = pd.read_csv(TEST_SET).sample(frac=t_frac, random_state=47)\n",
    "    #df = df.astype('int64')\n",
    "    #df_test = df_test.astype('int64')\n",
    "\n",
    "    attr_list = list(df[df.columns.difference(['decision'])])\n",
    "    dict_table ={}\n",
    "\n",
    "    # Labels\n",
    "    dict_labels = {}\n",
    "    dict_labels['no'] = len(df[df['decision'] == 0])\n",
    "    dict_labels['yes'] = len(df[df['decision'] == 1])\n",
    "    dict_table['decision'] = dict_labels\n",
    "    \n",
    "    # Attributes in discrete_columns\n",
    "    for attr in attr_list:\n",
    "        dict_attr = {}\n",
    "        attr_bin = max(int(df[attr].max()), int(df_test[attr].max()))\n",
    "        \n",
    "        dict_attr['no'] = [1 for i in range(attr_bin + 1)]\n",
    "        dict_attr['yes'] = [1 for i in range(attr_bin + 1)]\n",
    "        \n",
    "        for i in range(attr_bin+1):\n",
    "            dict_attr['no'][i] += len(df[(df[attr] == i) & (df['decision'] == 0)])\n",
    "            dict_attr['yes'][i] += len(df[(df[attr] == i) & (df['decision'] == 1)])\n",
    "\n",
    "        dict_table[attr] = dict_attr\n",
    "        \n",
    "    return dict_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy\n",
    "dict_table = nbc(1)\n",
    "\n",
    "# Accuracy on training data\n",
    "df = pd.read_csv(TRAINING_SET).sample(frac=1, random_state=47)\n",
    "(row, col) = df.shape\n",
    "attr_list = list(df[df.columns.difference(['decision'])])\n",
    "\n",
    "neg_num = len(df[df['decision'] == 0])\n",
    "pos_num = len(df[df['decision'] == 1])\n",
    "\n",
    "#print row\n",
    "correct = 0\n",
    "for i in range(row):\n",
    "    pd_pos = 1.0 * dict_table['decision']['yes']/row\n",
    "    pd_neg = 1.0 * dict_table['decision']['no']/row\n",
    "    #print pd_pos, pd_neg\n",
    "    for attr in attr_list:\n",
    "        pd_pos *= 1.0 * dict_table[attr]['yes'][int(df[attr][i])]/pos_num\n",
    "        pd_neg *= 1.0 * dict_table[attr]['no'][int(df[attr][i])]/neg_num\n",
    "    \n",
    "    res = np.argmax([1.0 * pd_neg, 1.0 * pd_pos])\n",
    "    if res == df['decision'][i]:\n",
    "        correct += 1\n",
    "#print correct\n",
    "training_accuracy = 1.0 * correct/row\n",
    "print 'Training Accuracy:', '%.2f' % training_accuracy\n",
    "#print 'Training Accuracy:', training_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(TEST_SET).sample(frac=1, random_state=47)\n",
    "(row_test, col_test) = df_test.shape\n",
    "#attr_list = list(df_test[df_test.columns.difference(['decision'])])\n",
    "\n",
    "neg_num = len(df_test[df_test['decision'] == 0])\n",
    "pos_num = len(df_test[df_test['decision'] == 1])\n",
    "\n",
    "correct = 0\n",
    "for i in range(row_test):\n",
    "    pd_pos = 1.0 * dict_table['decision']['yes']/row\n",
    "    pd_neg = 1.0 * dict_table['decision']['no']/row\n",
    "    #print pd_pos, pd_neg\n",
    "    for attr in attr_list:\n",
    "        pd_pos *= 1.0 * dict_table[attr]['yes'][int(df_test[attr][i])]/pos_num\n",
    "        pd_neg *= 1.0 * dict_table[attr]['no'][int(df_test[attr][i])]/neg_num\n",
    "    \n",
    "    res = np.argmax([1000.0 * pd_neg, 1000.0 * pd_pos])\n",
    "    if res == df_test['decision'][i]:\n",
    "        correct += 1\n",
    "#print correct tt\n",
    "test_accuracy = 1.0 * correct/row_test\n",
    "print 'Test Accuracy:', '%.2f' % test_accuracy\n",
    "#print 'Test Accuracy:', test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
